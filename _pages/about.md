---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Hello, I am Ahmed Salem, I am a Postdoc researcher at Microsoft Security Response Center (MSRC). Previous i was a PhD candidate working in the group of [Michael Backes](https://cispa.de/en/about/director-page) at CISPA, Saarland University.

My research interests are mainly: Machine learning privacy, biomedical data's privacy and applied cryptography. 

<h1>Whatâ€™s New</h1>
<ul>
  <li>Our paper "Bayesian Estimation of Differential Privacy" got accepted in ICML 2023</li>
  <li>Our paper "Analyzing Leakage of Personally Identifiable Information in Language Models" got accepted in Oakland 2023</li>
  <li>Our paper "SoK: Let the Privacy Games Begin! A Unified Treatment of Data Inference Privacy in Machine Learning" got accepted in Oakland 2023</li>
  <li>Our paper "Two-in-One: A Model Hijacking Attack Against Text Generation Models" got accepted in USENIX Security 2023</li>
  <li>Our paper "UnGANable: Defending Against GAN-based Face Manipulation" got accepted in USENIX Security 2023</li>

  <li>I started a PostDoc at Microsoft Research!</li>
  <li>Our paper "Get a Model! Model Hijacking Attack Against Machine Learning Models" got accepted in NDSS 2022</li>
  <li>Our paper "ML-Doctor: Holistic Risk Assessment of Inference Attacks Against Machine Learning Models
" got accepted in USENIX Security 2022</li>
  <li>Our paper "BadNL: Backdoor Attacks against NLP Models with Semantic-preserving Improvements" got accepted in ACSAC 2021</li>
  <li>I will spend 3 months as a research intern at Microsoft Research (MSR) Cambridge!</li>
  <li>Our technical report titled "Dynamic Backdoor Attacks Against Machine Learning Models" is now online</li>
    <li>Our paper "Updates-Leak: Data Set Inference and Reconstruction Attacks in Online Learning" got accepted in USENIX Security 2020!</li>

   <li>Our paper "MemGuard: Defending against Black-Box Membership Inference Attacks via Adversarial Examples" got accepted in CCS 2019!</li>
  <li>Our technical report titled "Updates-Leak: Data Set Inference and Reconstruction Attacks in Online Learning" is now online</li>
 

  <li>Our paper "ML-Leaks: Model and Data Independent Membership Inference Attacks and Defenses on Machine Learning Models
" got accepted in NDSS 2019!</li>
  <li>Our paper titled "Privacy-preserving Similar Patient Queries for Combined Biomedical Data" got accepted in PoPETs 2019</li>
  <li>Our technical report titled "MLCapsule: Guarded Offline Deployment of Machine Learning as a Service" is now online</li>
  <li>Our new technical report on membership inference against machine learning models is now online, a previous version of it was presented in PiMLAI 2018</li>
</ul>

